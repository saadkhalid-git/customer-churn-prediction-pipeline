{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import shap\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from customer_churn_pridiction.config import PROCESSED_DATA_DIR, MLFLOW_DIR, MODELS_DIR, SHAP_PLOTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(PROCESSED_DATA_DIR / 'train.csv')\n",
    "test_data = pd.read_csv(PROCESSED_DATA_DIR / 'test.csv')\n",
    "target = 'Churn'\n",
    "\n",
    "X_train = train_data.drop(columns=[target])\n",
    "Y_train = train_data[target]\n",
    "X_test = test_data.drop(columns=[target])\n",
    "Y_test = test_data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = joblib.load(PROCESSED_DATA_DIR / 'standard_scaler.joblib')\n",
    "one_hot_encoder = joblib.load(PROCESSED_DATA_DIR / 'one_hot_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_encoded = one_hot_encoder.transform(X_train.select_dtypes(include=['object']))\n",
    "\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded, columns=one_hot_encoder.get_feature_names_out(X_train.select_dtypes(include=['object']).columns.tolist()))\n",
    "\n",
    "X_train = pd.concat([X_train.select_dtypes(exclude=['object']), X_train_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_encoded = one_hot_encoder.transform(X_test.select_dtypes(include=['object']))\n",
    "\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=one_hot_encoder.get_feature_names_out(X_test.select_dtypes(include=['object']).columns.tolist()))\n",
    "\n",
    "\n",
    "X_test = pd.concat([X_test.select_dtypes(exclude=['object']), X_test_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/31 00:38:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/customer-churn-prediction-pipeline/lib/python3.9/site-packages/shap/plots/_beeswarm.py:952: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  pl.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: XGBoost\n",
      "Train accuracy: 0.9727\n",
      "Test accuracy: 0.9383\n",
      "Classification report for test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       898\n",
      "           1       0.88      0.72      0.79       172\n",
      "\n",
      "    accuracy                           0.94      1070\n",
      "   macro avg       0.91      0.85      0.88      1070\n",
      "weighted avg       0.94      0.94      0.94      1070\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/customer-churn-prediction-pipeline/lib/python3.9/site-packages/shap/plots/_scatter.py:777: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  pl.show()\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/customer-churn-prediction-pipeline/lib/python3.9/site-packages/shap/plots/_waterfall.py:315: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/customer-churn-prediction-pipeline/lib/python3.9/site-packages/shap/plots/_beeswarm.py:952: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  pl.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error logging SHAP plots for XGBoost: [Errno 2] No such file or directory: '/Users/saadkhalid/Documents/epita/s2/ai_methodology/customer-churn-prediction-pipeline/shap/shap_force_plot_XGBoost.html'\n",
      "Model: XGBoost - completed and logged all SHAP plots and model artifacts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/31 00:38:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: RandomForest\n",
      "Train accuracy: 0.8778\n",
      "Test accuracy: 0.8832\n",
      "Classification report for test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       898\n",
      "           1       0.93      0.30      0.45       172\n",
      "\n",
      "    accuracy                           0.88      1070\n",
      "   macro avg       0.90      0.65      0.69      1070\n",
      "weighted avg       0.89      0.88      0.86      1070\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/customer-churn-prediction-pipeline/lib/python3.9/site-packages/shap/plots/_beeswarm.py:627: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  pl.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error logging SHAP plots for RandomForest: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 50\n",
      "Model: RandomForest - completed and logged all SHAP plots and model artifacts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/31 00:38:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: LogisticRegression\n",
      "Train accuracy: 0.8921\n",
      "Test accuracy: 0.8963\n",
      "Classification report for test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       898\n",
      "           1       0.75      0.53      0.62       172\n",
      "\n",
      "    accuracy                           0.90      1070\n",
      "   macro avg       0.83      0.75      0.78      1070\n",
      "weighted avg       0.89      0.90      0.89      1070\n",
      "\n",
      "Model: LogisticRegression - completed and logged all SHAP plots and model artifacts.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(MLFLOW_DIR)\n",
    "mlflow.set_experiment('customer_churn_prediction_experiment')\n",
    "\n",
    "models = [\n",
    "    ('XGBoost', xgb.XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=0)),\n",
    "    ('RandomForest', RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)),\n",
    "    ('LogisticRegression', LogisticRegression(max_iter=100, random_state=0))\n",
    "]\n",
    "\n",
    "# Loop through models\n",
    "for model_name, model in models:\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Fit the model and log parameters\n",
    "        model.fit(standard_scaler.transform(X_train), Y_train)\n",
    "        mlflow.log_param('model', model_name)\n",
    "\n",
    "        # Log parameters specific to the model\n",
    "        model_params = {\n",
    "            'XGBoost': {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1},\n",
    "            'RandomForest': {'n_estimators': 100, 'max_depth': 5},\n",
    "            'LogisticRegression': {'max_iter': 100}\n",
    "        }\n",
    "        for param, value in model_params[model_name].items():\n",
    "            mlflow.log_param(param, value)\n",
    "\n",
    "        # Predictions and accuracy\n",
    "        Y_train_pred = model.predict(standard_scaler.transform(X_train))\n",
    "        Y_test_pred = model.predict(standard_scaler.transform(X_test))\n",
    "        train_accuracy = accuracy_score(Y_train, Y_train_pred)\n",
    "        test_accuracy = accuracy_score(Y_test, Y_test_pred)\n",
    "        \n",
    "        mlflow.log_metric('train_accuracy', train_accuracy)\n",
    "        mlflow.log_metric('test_accuracy', test_accuracy)\n",
    "\n",
    "        # Log model and artifacts\n",
    "        mlflow.sklearn.log_model(model, 'model')\n",
    "        mlflow.log_artifact(PROCESSED_DATA_DIR / 'standard_scaler.joblib')\n",
    "        mlflow.log_artifact(PROCESSED_DATA_DIR / 'one_hot_encoder.joblib')\n",
    "\n",
    "        # Print results\n",
    "        print(f'\\nModel: {model_name}')\n",
    "        print(f'Train accuracy: {train_accuracy:.4f}')\n",
    "        print(f'Test accuracy: {test_accuracy:.4f}')\n",
    "        print('Classification report for test data:')\n",
    "        print(classification_report(Y_test, Y_test_pred))\n",
    "        \n",
    "        # SHAP explanations for tree-based models only\n",
    "        if model_name in ['XGBoost', 'RandomForest']:\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(standard_scaler.transform(X_test))\n",
    "            \n",
    "            try:\n",
    "                # Summary plot (bar)\n",
    "                plt.figure()\n",
    "                shap.summary_plot(shap_values, X_test, plot_type='bar')\n",
    "                summary_plot_path = os.path.join(SHAP_PLOTS_DIR, f'shap_summary_plot_{model_name}.png')\n",
    "                plt.savefig(summary_plot_path)\n",
    "                plt.close()  # Close the figure after saving\n",
    "\n",
    "                # Dependence plot\n",
    "                plt.figure()\n",
    "                shap.dependence_plot('Tenure', shap_values, X_test)\n",
    "                dependence_plot_path = os.path.join(SHAP_PLOTS_DIR, f'shap_dependence_plot_tenure_{model_name}.png')\n",
    "                plt.savefig(dependence_plot_path)\n",
    "                plt.close()  # Close the figure after saving\n",
    "                \n",
    "                # Waterfall plot for a single instance\n",
    "                plt.figure()\n",
    "                shap.waterfall_plot(shap.Explanation(values=shap_values[0], base_values=explainer.expected_value, data=X_test.iloc[0]))\n",
    "                waterfall_plot_path = os.path.join(SHAP_PLOTS_DIR, f'shap_waterfall_plot_{model_name}.png')\n",
    "                plt.savefig(waterfall_plot_path)\n",
    "                plt.close()  # Close the figure after saving\n",
    "\n",
    "                # Beeswarm plot\n",
    "                plt.figure()\n",
    "                shap.summary_plot(shap_values, X_test, plot_type='dot')\n",
    "                beeswarm_plot_path = os.path.join(SHAP_PLOTS_DIR, f'shap_beeswarm_plot_{model_name}.png')\n",
    "                plt.savefig(beeswarm_plot_path)\n",
    "                plt.close()  # Close the figure after saving\n",
    "                \n",
    "                # Force plot (specific data point)\n",
    "                force_plot_path = os.path.join(SHAP_PLOTS_DIR, f'shap_force_plot_{model_name}.html')\n",
    "                shap.force_plot(explainer.expected_value, shap_values[0], X_test.iloc[0], show=False)\n",
    "                plt.close()  # Close any opened figures (if applicable)\n",
    "\n",
    "                mlflow.log_artifact(force_plot_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error logging SHAP plots for {model_name}: {e}\")\n",
    "\n",
    "        # Dump model after training\n",
    "        model_dump_path = f\"{model_name}_model.joblib\"\n",
    "        model_full_path = MODELS_DIR / model_dump_path\n",
    "\n",
    "        joblib.dump(model, model_full_path)\n",
    "        mlflow.log_artifact(model_full_path)\n",
    "\n",
    "    print(f'Model: {model_name} - completed and logged all SHAP plots and model artifacts.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customer-churn-prediction-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
